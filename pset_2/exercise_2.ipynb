{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Bloom filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a Bloom filter using bitarray\n",
    "import bitarray as bit\n",
    "from hashlib import sha3_256, sha256, blake2b\n",
    "\n",
    "class BloomFilter:\n",
    "    def __init__(self, size, hashes):\n",
    "        self.size = size # Specify filter size\n",
    "        self.hashes = hashes # Specify desired hash functions\n",
    "        self.bitarray = bit.bitarray(size) # Initialize bitarray with defined size\n",
    "\n",
    "    # Define hash functions\n",
    "    def my_hash(self, value):\n",
    "        return int(sha256(value.lower().encode()).hexdigest(), 16) % self.size\n",
    "\n",
    "    def my_hash2(self, value):\n",
    "        return int(blake2b(value.lower().encode()).hexdigest(), 16) % self.size\n",
    "\n",
    "    def my_hash3(self, value):\n",
    "        return int(sha3_256(value.lower().encode()).hexdigest(), 16) % self.size \n",
    "    \n",
    "    # Add a value to the Bloom filter\n",
    "    def add(self, value):\n",
    "        for hash in self.hashes:\n",
    "            hashed = hash(self, value) # Access hash functions as instance methods for flexibility to choose combinations\n",
    "            index = hashed % self.size # Convert hashed value to index\n",
    "            self.bitarray[index] = 1 # Set index position in bitarray to 1\n",
    "\n",
    "    # Check if a value is in the Bloom filter (may return false positives)\n",
    "    def lookup(self, value):\n",
    "        for hash in self.hashes:\n",
    "            hashed = hash(self, value) # Access hash functions as instance methods\n",
    "            index = hashed % self.size # Convert hashed value to index\n",
    "            if self.bitarray[index] == 0: # Check if index position in bitarray is occupied\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Test the Bloom filter\n",
    "add_test = BloomFilter(size = 100, hashes = [BloomFilter.my_hash, BloomFilter.my_hash2, BloomFilter.my_hash3])\n",
    "add_test.add(\"Hello!\")\n",
    "print(add_test.lookup(\"Hello!\"))   # True (potentially a false positive)\n",
    "print(add_test.lookup(\"Goodbye!\")) # False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Store words.txt into Bloom filter (assuming all words are correctly spelled)\n",
    "# Note: To avoid hash collisions, the absolute minimum for a corpus of 500,000 words with 3 hash functions is 150,000 bits.\n",
    "# For a starting point, at least 1,000,000 bits is recommended; 10,000,000 bits to be safe.\n",
    "words = BloomFilter(size = 10_000_000, hashes = [BloomFilter.my_hash, BloomFilter.my_hash2, BloomFilter.my_hash3])\n",
    "\n",
    "with open(\"words.txt\") as file:\n",
    "    # Read word list one at a time\n",
    "    for line in file:\n",
    "        word = line.strip()\n",
    "        words.add(word)\n",
    "\n",
    "# Test the filter\n",
    "print(words.lookup(\"cb&b634\"))       # False\n",
    "print(words.lookup(\"computational\")) # True\n",
    "print(words.lookup(\"methods\"))       # True\n",
    "print(words.lookup(\"for\"))           # True\n",
    "print(words.lookup(\"informatics\"))   # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pruh', 'bluh', 'brum', 'brut']\n",
      "'moment' is spelled correctly.\n"
     ]
    }
   ],
   "source": [
    "# Bloom filter spell checker\n",
    "# Note: May return more false positives (suggesting a word not in the list) with smaller filters and fewer hash functions.\n",
    "def spell_checker(word, BloomFilter):\n",
    "    # If the word is in the specified Bloom filter, it is correctly spelled\n",
    "    if BloomFilter.lookup(word):\n",
    "        return(f\"'{word}' is spelled correctly.\")\n",
    "    \n",
    "    # If not, generate all possible single-letter substitutions and test them against Bloom filter\n",
    "    word_suggestions = []\n",
    "    for i in range(len(word)):\n",
    "        for letter in \"abcdefghijklmnopqrstuvwxyz\":\n",
    "            candidate = word[:i] + letter + word[i+1:] # Slice word to test every letter at every character position\n",
    "            if BloomFilter.lookup(candidate):\n",
    "                word_suggestions.append(candidate)\n",
    "\n",
    "    # Return candidate words\n",
    "    return word_suggestions\n",
    "\n",
    "print(spell_checker(\"bruh\", words))\n",
    "print(spell_checker(\"moment\", words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestion accuracy: 45.8 %\n"
     ]
    }
   ],
   "source": [
    "# Test spell checker on typos.json\n",
    "import json\n",
    "\n",
    "def accuracy_checker(BloomFilter):\n",
    "    # Load list of typos\n",
    "    with open(\"typos.json\") as file:\n",
    "        typos = json.load(file) # Creates list of [typed_word, correct_word] pairs\n",
    "    correct_count = 0\n",
    "    \n",
    "    # Check if correct word is produced by the specified Bloom filter and that it gives no more than 3 suggestions\n",
    "    for typo in typos:\n",
    "        if (typo[1] in spell_checker(typo[0], BloomFilter)) and (len(spell_checker(typo[0], BloomFilter)) <= 3):\n",
    "            correct_count = correct_count + 1\n",
    "\n",
    "    # Return spell checker accuracy\n",
    "    return(correct_count / len(typos))\n",
    "\n",
    "print(\"Suggestion accuracy:\", round(accuracy_checker(words) * 100, 3), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 100000.,  200000.,  300000.,  400000.,  500000.,  600000.,\n",
       "        700000.,  800000.,  900000., 1000000., 1100000., 1200000.,\n",
       "       1300000., 1400000., 1500000., 1600000., 1700000., 1800000.,\n",
       "       1900000., 2000000., 2100000., 2200000., 2300000., 2400000.,\n",
       "       2500000., 2600000., 2700000., 2800000., 2900000., 3000000.,\n",
       "       3100000., 3200000., 3300000., 3400000., 3500000., 3600000.,\n",
       "       3700000., 3800000., 3900000., 4000000., 4100000., 4200000.,\n",
       "       4300000., 4400000., 4500000., 4600000., 4700000., 4800000.,\n",
       "       4900000., 5000000., 5100000., 5200000., 5300000., 5400000.,\n",
       "       5500000., 5600000., 5700000., 5800000., 5900000., 6000000.,\n",
       "       6100000., 6200000., 6300000., 6400000., 6500000., 6600000.,\n",
       "       6700000., 6800000., 6900000., 7000000., 7100000., 7200000.,\n",
       "       7300000., 7400000., 7500000., 7600000., 7700000., 7800000.,\n",
       "       7900000., 8000000., 8100000., 8200000., 8300000., 8400000.,\n",
       "       8500000., 8600000., 8700000., 8800000., 8900000., 9000000.,\n",
       "       9100000., 9200000., 9300000., 9400000., 9500000., 9600000.,\n",
       "       9700000., 9800000., 9900000.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot filter size against hash function choice (first, first two, all three)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sizes = list(np.linspace(start = 1e5, stop = 1e7, num = 10, dtype = int)) # Generate evenly spaced Bloom filter sizes\n",
    "accuracies = []\n",
    "for size in sizes:\n",
    "    one_hash_filter = BloomFilter(size = size, hashes = [BloomFilter.my_hash])\n",
    "    accuracies.append()\n",
    "\n",
    "    two_hash_filter = BloomFilter(size = size, hashes = [BloomFilter.my_hash, BloomFilter.my_hash2])\n",
    "    three_hash_filter = BloomFilter(size = size, hashes = [BloomFilter.my_hash, BloomFilter.my_hash2, BloomFilter.my_hash3])\n",
    "\n",
    "one_hash_results = pd.DataFrame({\"filter_size\": sizes, \"accuracy\": accuracies})\n",
    "two_hash_results = pd.DataFrame({\"filter_size\": sizes, \"accuracy\": accuracies})\n",
    "three_hash_results = pd.DataFrame({\"filter_size\": sizes, \"accuracy\": accuracies})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
