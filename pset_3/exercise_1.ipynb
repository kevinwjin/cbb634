{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies\n",
    "Execute the following in the terminal before running any notebooks:\n",
    "`pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: 1000 Alzheimer's disease and 1000 cancer papers from PubMed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['21473028',\n",
       " '21210563',\n",
       " '18958642',\n",
       " '18202459',\n",
       " '17822285',\n",
       " '17642789',\n",
       " '17642773',\n",
       " '17642626',\n",
       " '17642623',\n",
       " '17491665']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query Entrez API for PubMed IDs of search term and year and return as a list\n",
    "import requests\n",
    "\n",
    "def get_pmids(term, year, retmax):\n",
    "    # Define efetch URL\n",
    "    url = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term={term}+AND+{year}[pdat]&retmode=json&retmax={retmax}\"\n",
    "    \n",
    "    # Query the Entrez API\n",
    "    r = requests.get(url)\n",
    "\n",
    "    # Grab the list of PMIDs\n",
    "    pmids = r.json()[\"esearchresult\"][\"idlist\"]\n",
    "    \n",
    "    return pmids\n",
    "\n",
    "get_pmids(\"lupus\", \"2004\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Entrez for metadata of a PubMed paper given its PMID\n",
    "from lxml import etree\n",
    "\n",
    "# def get_full_abstract(abstract_elements):\n",
    "#     # Concatenate all abstract text elements to form the full abstract\n",
    "#     full_abstract = ' '.join([abstract_elem.text for abstract_elem in abstract_elements if abstract_elem.text])\n",
    "#     return full_abstract\n",
    "\n",
    "def get_metadata(pmids):\n",
    "    # Convert list of PMIDs to a string for POST payload\n",
    "    pmids_string = \",\".join(pmids)\n",
    "\n",
    "    url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
    "\n",
    "    # Define parameters for POST payload\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'id': pmids_string,\n",
    "        'retmode': 'xml'\n",
    "    }\n",
    "\n",
    "    # Query the Entrez API\n",
    "    r = requests.post(url, params)\n",
    "\n",
    "    # Parse the XML response if the response was successful\n",
    "    if r.status_code == 200:\n",
    "        doc = etree.fromstring(r.text)\n",
    "        titles = doc.xpath(\"//ArticleTitle\")\n",
    "        abstracts = doc.xpath(\"//AbstractText\")\n",
    "        queries = [\"alzheimers\"] * 1000 + [\"cancer\"] * 1000\n",
    "\n",
    "        papers_dict = {}\n",
    "        for i, pmid in enumerate(pmids):\n",
    "            full_abstract = get_full_abstract(abstracts[i])\n",
    "\n",
    "            papers_dict[pmid] = {\n",
    "                \"ArticleTitle\": etree.tostring(titles[i], method = \"text\", encoding='unicode'),\n",
    "                \"AbstractText\": etree.tostring(abstracts[i], method = \"text\", encoding='unicode'),\n",
    "                #\"AbstractText\": full_abstract,\n",
    "                \"query\": queries[i]\n",
    "            } \n",
    "        return papers_dict\n",
    "    \n",
    "    else:\n",
    "        print(f\"Error: {r.status_code}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all 2000 papers and save metadata to JSON file\n",
    "import json\n",
    "\n",
    "pmids = get_pmids(\"alzheimers\", \"2023\", 1000) + get_pmids(\"cancer\", \"2023\", 1000)\n",
    "papers_dict = get_metadata(pmids)\n",
    "\n",
    "with open(\"papers_dict.json\", \"w\") as f:\n",
    "    json.dump(papers_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following PMIDs appear in both the Alzheimer's and the cancer sets of papers: ['37937963', '37936448', '37933846', '37933726']\n"
     ]
    }
   ],
   "source": [
    "# Find PMID overlap\n",
    "split = len(pmids) // 2\n",
    "alzheimers, cancer = pmids[split:], pmids[:split]\n",
    "\n",
    "def intersection(list_1, list_2):\n",
    "    overlap = [value for value in list_1 if value in list_2]\n",
    "    return overlap\n",
    "\n",
    "print(f\"The following PMIDs appear in both the Alzheimer's and the cancer sets of papers: {intersection(alzheimers, cancer)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
